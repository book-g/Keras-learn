<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Layer Weight Initializers</title>
    <link rel="stylesheet" href="../../../styles.css">

    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.2/katex.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.2/katex.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.2/contrib/auto-render.min.js"></script>
   
</head>
<body>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
                delimiters: [
                    { left: "$$", right: "$$", display: true },
                    { left: "$", right: "$", display: false }
                ]
            });
        });
    </script>
    <div class="layout">
        <main class="content-area">
            <h1>Layer Weight Initializers</h1>
            <div class="card-grid">
                <a href="https://engineer-ece.github.io/Keras-learn/Keras3/02.%20Layers%20API/03. Layer weight initializers/01. RandomNormal class/readme/chatgpt" class="card">
                    <div class="card-image">
                        <img src="https://engineer-ece.github.io/Keras-learn/Keras3/02. Layers API/03. Layer weight initializers/01. RandomNormal class/random_normal_distribution.png" alt="Example Image">
                    </div>
                    <div class="card-title">
                        <h2>RandomNormal</h2>
                    </div>
                    <div class="card-content">
                        <p class="equation">
<div style="text-align: left;">
    The RandomNormal initializer in Keras is used to initialize the weights of layers in a neural network with values drawn from a normal (Gaussian) distribution. The formula for generating a random weight using the RandomNormal initializer is:
</div>

\[ W \sim \mathcal{N}(\text{mean}, \text{stddev}^2) \]

<div style="text-align: left;">
 Where:
<li> \( W \) represents the initialized weight.
<li> \( \mathcal{N} \) denotes a normal distribution.
<li> <b>mean</b> is the mean of the distribution.
<li> <b>stddev</b> is the standard deviation of the distribution.
</div>
<br>
<div style="text-align: left;">
 Parameters in Keras:
<li> <b>mean</b>: The mean of the normal distribution (default is 0.0).
<li> <b>stddev</b>: The standard deviation of the normal distribution (default is 0.05).
<li> <b>seed</b>: An optional integer used to seed the random number generator for reproducibility.
</div>

                        </p>
                    </div>
                </a>

                <a href="https://engineer-ece.github.io/Keras-learn/Keras3/02.%20Layers%20API/03. Layer weight initializers/01. RandomUniform class/readme/chatgpt" class="card">
                    <div class="card-image">
                        <img src="https://engineer-ece.github.io/Keras-learn/Keras3/02. Layers API/03. Layer weight initializers/02. RandomUniform class/random_uniform_distribution.png" alt="Example Image">
                    </div>
                    <div class="card-title">
                        <h2>RandomUniform</h2>
                    </div>
                    <div class="card-content">
                        <p class="equation">
<div style="text-align: left;">                            
    The <b>RandomUniform</b> initializer in Keras generates weights by drawing samples from a uniform distribution within a specified range. The formula for generating a weight \( W \) using this initializer is:

\[ W \sim \text{Uniform}(\text{minval}, \text{maxval}) \]


Where: 
<div>
<li> \( W \) represents the initialized weight.
<li> <b>Uniform</b> denotes the uniform distribution.
<li> <b>minval</b> is the lower bound of the uniform distribution.
<li> <b>maxval</b> is the upper bound of the uniform distribution.
</div>
<br><br> This means that each weight is randomly selected from a uniform distribution that lies between `minval` and `maxval`. By default, `minval` is \(-0.05\) and `maxval` is \(0.05\).
                        
</div>

</p>
                    </div>
                </a>
                <a href="https://engineer-ece.github.io/Keras-learn/Keras3/02.%20Layers%20API/03. Layer weight initializers/03. TruncatedNormal class/readme/chatgpt" class="card">
                    <div class="card-image">
                        <img src="https://engineer-ece.github.io/Keras-learn/Keras3/02. Layers API/03. Layer weight initializers/03. TruncatedNormal class/truncated_normal_distribution.png" alt="Example Image">
                    </div>
                    <div class="card-title">
                        <h2>TruncatedNormal</h2>
                    </div>
                    <div class="card-content" >
                        <p class="equation">
                            <div style="text-align: left;">
                    

    

    <h3>Probability Density Function (PDF)</h3>
    <p>
        The PDF of the truncated normal distribution is given by:
    </p>
    <p>
        \[
        f(x) = \frac{\phi\left(\frac{x - \mu}{\sigma}\right)}{\Phi\left(\frac{b - \mu}{\sigma}\right) - \Phi\left(\frac{a - \mu}{\sigma}\right)}
        \]
    </p>
    <p>
        where:
        <ul>
            <li>
                \(\phi\) is the PDF of the standard normal distribution:
                \[
                \phi(z) = \frac{1}{\sqrt{2 \pi}} e^{-\frac{z^2}{2}}
                \]
            </li>
            <li>
                \(\Phi\) is the CDF of the standard normal distribution:
                \[
                \Phi(z) = \int_{-\infty}^z \phi(t) \, dt
                \]
            </li>
            <li>\(\mu\) is the mean of the original normal distribution.</li>
            <li>\(\sigma\) is the standard deviation of the original normal distribution.</li>
            <li>\(a\) and \(b\) are the lower and upper bounds for truncation.</li>
        </ul>
    </p>

    <h3>Cumulative Distribution Function (CDF)</h3>
    <p>
        The CDF of the truncated normal distribution is:
    </p>
    <p>
        \[
        F(x) = \frac{\Phi\left(\frac{x - \mu}{\sigma}\right) - \Phi\left(\frac{a - \mu}{\sigma}\right)}{\Phi\left(\frac{b - \mu}{\sigma}\right) - \Phi\left(\frac{a - \mu}{\sigma}\right)}
        \]
    </p>
    <p>
        where:
        <ul>
            <li>\(\Phi\) is the CDF of the standard normal distribution.</li>
        </ul>
    </p>

    
    
   
</div>
                        </p>

                    </div>
                </a>



                
             
                <!-- Add more cards as needed -->
            </div>
        </main>
    </div>
</body>
</html>
